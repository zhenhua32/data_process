{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>政务_文旅</td>\n",
       "      <td>安徽三祖寺发现佛牙舍利 初步判断为宋代皇家所赐</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>科技_数码</td>\n",
       "      <td>员工曝苹果2022年春季发布会要来了！iPhone SE 3即将发布</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>汽车_行业</td>\n",
       "      <td>俄乌战争使大众向中国和美国转移产能</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>科技_车科技</td>\n",
       "      <td>再也不怕事故扯皮！所有新车全面上线黑匣子：比行车记录仪好用</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>体育_中国足球</td>\n",
       "      <td>终身禁赛！体育总局和公安部联手严查严打赌球假球行为</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>政务_发展治理</td>\n",
       "      <td>住建部约谈五城背后：东莞房价涨幅超深圳、房企南通激战抢地</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3916</th>\n",
       "      <td>体育_NBA</td>\n",
       "      <td>欧文回应与哈登不和传言：别把我名字放到这些傻瓜文章里！</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3917</th>\n",
       "      <td>政务_发展治理</td>\n",
       "      <td>统计局：中国3月CPI同比增长0.4%，环比下降0.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3918</th>\n",
       "      <td>娱乐_电影</td>\n",
       "      <td>她这组写真照真不错</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3919</th>\n",
       "      <td>体育_国际足球</td>\n",
       "      <td>球迷怒斥金球奖颁给梅西是耻辱 竟收获C罗寄来的签名球衣</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3920 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        label                           sentence1\n",
       "0       政务_文旅             安徽三祖寺发现佛牙舍利 初步判断为宋代皇家所赐\n",
       "1       科技_数码  员工曝苹果2022年春季发布会要来了！iPhone SE 3即将发布\n",
       "2       汽车_行业                   俄乌战争使大众向中国和美国转移产能\n",
       "3      科技_车科技       再也不怕事故扯皮！所有新车全面上线黑匣子：比行车记录仪好用\n",
       "4     体育_中国足球           终身禁赛！体育总局和公安部联手严查严打赌球假球行为\n",
       "...       ...                                 ...\n",
       "3915  政务_发展治理        住建部约谈五城背后：东莞房价涨幅超深圳、房企南通激战抢地\n",
       "3916   体育_NBA         欧文回应与哈登不和传言：别把我名字放到这些傻瓜文章里！\n",
       "3917  政务_发展治理        统计局：中国3月CPI同比增长0.4%，环比下降0.5%\n",
       "3918    娱乐_电影                           她这组写真照真不错\n",
       "3919  体育_国际足球         球迷怒斥金球奖颁给梅西是耻辱 竟收获C罗寄来的签名球衣\n",
       "\n",
       "[3920 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./ifeng_data/train.csv\", header=None, sep=\"\\t\", names=[\"label\", \"sentence1\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['体育', '娱乐', '政务', '时尚', '汽车', '科技'] 6\n",
      "['5G', 'CBA', 'NBA', '中国足球', '区块链', '反腐', '发展治理', '国际足球', '地方', '导购', '情感', '手机', '政策', '数码', '文旅', '新车', '时装', '明星', '电影', '电视', '美容', '行业', '试驾', '车科技', '音乐'] 25\n"
     ]
    }
   ],
   "source": [
    "labels = sorted(df[\"label\"].value_counts().index.tolist())\n",
    "\n",
    "labels1 = sorted(set([x.split(\"_\")[0] for x in labels]))\n",
    "labels2 = sorted(set([x.split(\"_\")[1] for x in labels]))\n",
    "print(labels1, len(labels1))\n",
    "print(labels2, len(labels2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "科技_数码      247\n",
       "科技_手机      234\n",
       "体育_NBA     172\n",
       "娱乐_音乐      166\n",
       "时尚_时装      165\n",
       "时尚_美容      163\n",
       "科技_车科技     162\n",
       "政务_地方      161\n",
       "体育_国际足球    161\n",
       "体育_中国足球    160\n",
       "娱乐_电影      159\n",
       "汽车_新车      159\n",
       "政务_发展治理    158\n",
       "政务_反腐      157\n",
       "汽车_试驾      157\n",
       "体育_CBA     157\n",
       "娱乐_电视      155\n",
       "娱乐_明星      155\n",
       "时尚_情感      153\n",
       "汽车_行业      152\n",
       "政务_政策      149\n",
       "科技_区块链     146\n",
       "政务_文旅      106\n",
       "汽车_导购       84\n",
       "科技_5G       82\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'体育': 0, '娱乐': 1, '政务': 2, '时尚': 3, '汽车': 4, '科技': 5}\n",
      "{'5G': 0, 'CBA': 1, 'NBA': 2, '中国足球': 3, '区块链': 4, '反腐': 5, '发展治理': 6, '国际足球': 7, '地方': 8, '导购': 9, '情感': 10, '手机': 11, '政策': 12, '数码': 13, '文旅': 14, '新车': 15, '时装': 16, '明星': 17, '电影': 18, '电视': 19, '美容': 20, '行业': 21, '试驾': 22, '车科技': 23, '音乐': 24}\n"
     ]
    }
   ],
   "source": [
    "labels1_dict = dict(zip(labels1, range(len(labels1))))\n",
    "labels2_dict = dict(zip(labels2, range(len(labels2))))\n",
    "print(labels1_dict)\n",
    "print(labels2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'体育': 650, '娱乐': 635, '政务': 731, '时尚': 481, '汽车': 552, '科技': 871}\n",
      "{'5G': 82, 'CBA': 157, 'NBA': 172, '中国足球': 160, '区块链': 146, '反腐': 157, '发展治理': 158, '国际足球': 161, '地方': 161, '导购': 84, '情感': 153, '手机': 234, '政策': 149, '数码': 247, '文旅': 106, '新车': 159, '时装': 165, '明星': 155, '电影': 159, '电视': 155, '美容': 163, '行业': 152, '试驾': 157, '车科技': 162, '音乐': 166}\n",
      "[1.34, 1.3716535433070867, 1.1915184678522572, 1.8108108108108107, 1.5778985507246377, 1.0]\n",
      "[3.0121951219512195, 1.5732484076433122, 1.436046511627907, 1.54375, 1.6917808219178083, 1.5732484076433122, 1.5632911392405062, 1.5341614906832297, 1.5341614906832297, 2.9404761904761907, 1.6143790849673203, 1.0555555555555556, 1.657718120805369, 1.0, 2.330188679245283, 1.5534591194968554, 1.496969696969697, 1.5935483870967742, 1.5534591194968554, 1.5935483870967742, 1.5153374233128833, 1.625, 1.5732484076433122, 1.5246913580246915, 1.4879518072289157]\n"
     ]
    }
   ],
   "source": [
    "labels1_weight_dict = dict((x, 0) for x in labels1_dict.keys())\n",
    "labels2_weight_dict = dict((x, 0) for x in labels2_dict.keys())\n",
    "for label in df[\"label\"]:\n",
    "    label1, label2 = label.strip().split(\"_\")\n",
    "    labels1_weight_dict[label1] += 1\n",
    "    labels2_weight_dict[label2] += 1\n",
    "\n",
    "assert len(labels1_weight_dict) == len(labels1_dict)\n",
    "assert len(labels2_weight_dict) == len(labels2_dict)\n",
    "\n",
    "print(labels1_weight_dict)\n",
    "print(labels2_weight_dict)\n",
    "\n",
    "# 用当前最大的类别数, 除以当前类别数\n",
    "labels1_weight_list = []\n",
    "max_labels = max(labels1_weight_dict.values())\n",
    "for label, label_id in labels1_dict.items():\n",
    "    labels1_weight_list.append(max_labels / labels1_weight_dict[label])\n",
    "\n",
    "labels2_weight_list = []\n",
    "max_labels = max(labels2_weight_dict.values())\n",
    "for label, label_id in labels2_dict.items():\n",
    "    labels2_weight_list.append(max_labels / labels2_weight_dict[label])\n",
    "\n",
    "print(labels1_weight_list)\n",
    "print(labels2_weight_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, BertModel\n",
    "import torch\n",
    "import torch.nn  as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='bert-base-chinese', vocab_size=21128, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3920\n",
      "980\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv(\"./ifeng_data/train.csv\", header=None, sep=\"\\t\", names=[\"label\", \"sentence1\"])\n",
    "df_test = pd.read_csv(\"./ifeng_data/test.csv\", header=None, sep=\"\\t\", names=[\"label\", \"sentence1\"])\n",
    "print(len(df_train))\n",
    "print(len(df_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        label = self.df.iloc[idx, 0]\n",
    "        label1, label2 = label.strip().split(\"_\")\n",
    "        label1 = labels1_dict[label1]\n",
    "        label2 = labels2_dict[label2]\n",
    "\n",
    "        sentence1 = self.df.iloc[idx, 1]\n",
    "        sentence1 = tokenizer(sentence1, padding=\"max_length\", truncation=True, max_length=32)\n",
    "        input_ids = torch.tensor(sentence1[\"input_ids\"])\n",
    "        attention_mask = torch.tensor(sentence1[\"attention_mask\"])\n",
    "        token_type_ids = torch.tensor(sentence1[\"token_type_ids\"])\n",
    "        return input_ids, attention_mask, token_type_ids, label1, label2\n",
    "\n",
    "dataset_train = MyDataset(df_train)\n",
    "dataset_test = MyDataset(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 101, 2128, 2551,  676, 4862, 2191, 1355, 4385,  867, 4280, 5650, 1164,\n",
       "         1159, 3635, 1161, 3171,  711, 2129,  807, 4640, 2157, 2792, 6606,  102,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0]),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 2,\n",
       " 14)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "input_ids, attention_mask, token_type_ids, label1, label2 = next(iter(dataloader_train))\n",
    "print(input_ids.shape)\n",
    "print(attention_mask.shape)\n",
    "print(token_type_ids.shape)\n",
    "print(label1.shape)\n",
    "print(label2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-chinese were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MyModel(\n",
       "  (bert_model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc1): Linear(in_features=768, out_features=6, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (fc2): Linear(in_features=768, out_features=25, bias=True)\n",
       "  (dropout2): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bert_model = BertModel.from_pretrained(\"bert-base-chinese\")\n",
    "        self.fc1 = nn.Linear(self.bert_model.config.hidden_size, len(labels1))\n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(self.bert_model.config.hidden_size, len(labels2))\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert_model(input_ids, attention_mask, token_type_ids)\n",
    "        pooled_output = output[1]\n",
    "\n",
    "        pooled_output1 = self.dropout1(pooled_output)\n",
    "        pooled_output2 = self.dropout2(pooled_output)\n",
    "\n",
    "        logits1 = self.fc1(pooled_output1)\n",
    "        logits2 = self.fc2(pooled_output2)\n",
    "        return logits1, logits2\n",
    "\n",
    "model = MyModel()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_func1 = nn.CrossEntropyLoss(weight=torch.tensor(labels1_weight_list).to(device))\n",
    "loss_func2 = nn.CrossEntropyLoss(weight=torch.tensor(labels2_weight_list).to(device))\n",
    "\n",
    "def train(dataloader: DataLoader, model: MyModel, loss_func1: nn.CrossEntropyLoss, loss_func2: nn.CrossEntropyLoss, optimizer: torch.optim.Optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "\n",
    "    for i, (input_ids, attention_mask, token_type_ids, label1, label2) in enumerate(dataloader):\n",
    "        input_ids, attention_mask, token_type_ids, label1, label2 = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device), label1.to(device), label2.to(device)\n",
    "        logits1, logits2 = model(input_ids, attention_mask, token_type_ids)\n",
    "        loss1 = loss_func1(logits1, label1)\n",
    "        loss2 = loss_func2(logits2, label2)\n",
    "        loss = loss1 + loss2\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            loss, current = loss.item(), i * len(input_ids)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader: DataLoader, model: MyModel, loss_func1: nn.CrossEntropyLoss, loss_func2: nn.CrossEntropyLoss):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct1, correct2 = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (input_ids, attention_mask, token_type_ids, label1, label2) in enumerate(dataloader):\n",
    "            input_ids, attention_mask, token_type_ids, label1, label2 = input_ids.to(device), attention_mask.to(device), token_type_ids.to(device), label1.to(device), label2.to(device)\n",
    "            logits1, logits2 = model(input_ids, attention_mask, token_type_ids)\n",
    "            loss1 = loss_func1(logits1, label1)\n",
    "            loss2 = loss_func2(logits2, label2)\n",
    "            loss = loss1 + loss2\n",
    "\n",
    "            test_loss += loss.item()\n",
    "            correct1 += (logits1.argmax(1) == label1).type(torch.float).sum().item()\n",
    "            correct2 += (logits2.argmax(1) == label2).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct1 /= size\n",
    "    correct2 /= size\n",
    "    print(f\"Test Error: \\n Accuracy1: {(100*correct1):>0.1f}%, Accuracy2: {(100*correct2):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 5.223433  [    0/ 3920]\n",
      "loss: 3.743813  [ 1600/ 3920]\n",
      "loss: 2.725682  [ 3200/ 3920]\n",
      "Test Error: \n",
      " Accuracy1: 86.6%, Accuracy2: 51.6%, Avg loss: 2.301221 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.192611  [    0/ 3920]\n",
      "loss: 1.930035  [ 1600/ 3920]\n",
      "loss: 1.141719  [ 3200/ 3920]\n",
      "Test Error: \n",
      " Accuracy1: 88.7%, Accuracy2: 68.3%, Avg loss: 1.602938 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.169758  [    0/ 3920]\n",
      "loss: 0.943214  [ 1600/ 3920]\n",
      "loss: 1.108432  [ 3200/ 3920]\n",
      "Test Error: \n",
      " Accuracy1: 90.5%, Accuracy2: 71.6%, Avg loss: 1.313833 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.140171  [    0/ 3920]\n",
      "loss: 0.621030  [ 1600/ 3920]\n",
      "loss: 0.831159  [ 3200/ 3920]\n",
      "Test Error: \n",
      " Accuracy1: 89.2%, Accuracy2: 73.8%, Avg loss: 1.247440 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 0.638040  [    0/ 3920]\n",
      "loss: 1.248185  [ 1600/ 3920]\n",
      "loss: 1.262491  [ 3200/ 3920]\n",
      "Test Error: \n",
      " Accuracy1: 90.7%, Accuracy2: 73.3%, Avg loss: 1.171722 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(dataloader_train, model, loss_func1, loss_func2, optimizer)\n",
    "    test(dataloader_test, model, loss_func1, loss_func2)\n",
    "print(\"Done!\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d8025d30852334e6e768ca567da121c1aa274c2c5a5a8a9ff400eded44c1a99b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('transformers')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
